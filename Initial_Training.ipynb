{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "p50Dd1C_-3Hi",
        "JmZ3f6rlljoj"
      ],
      "authorship_tag": "ABX9TyMtUbVu1PNR1KS2V2+Vg4Vr"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3e0952d256f8459eb1ab8d883fe314b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_66c597dafa524766b01547ea36fe19e8",
              "IPY_MODEL_f71059c1b5524ade9e0f95d706ba7068",
              "IPY_MODEL_86c8932bb8d044aeb8f703f2ee901c83"
            ],
            "layout": "IPY_MODEL_b8f80395b11b4804aa22ac75382ec8de"
          }
        },
        "66c597dafa524766b01547ea36fe19e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb363c5ac5494eb2ae1ae564cd43a857",
            "placeholder": "​",
            "style": "IPY_MODEL_2d0be03d4cc8451da5e3f01734490d8e",
            "value": "100%"
          }
        },
        "f71059c1b5524ade9e0f95d706ba7068": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fffc90992b3f48bfb37e76fb1c306166",
            "max": 111898327,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a8828e148a4c400cbd9edf2a71219619",
            "value": 111898327
          }
        },
        "86c8932bb8d044aeb8f703f2ee901c83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_508f6ab46abb40c4a117e256cd0f17a5",
            "placeholder": "​",
            "style": "IPY_MODEL_b5cf6378100044fab95e5565fb52f4e0",
            "value": " 107M/107M [00:00&lt;00:00, 231MB/s]"
          }
        },
        "b8f80395b11b4804aa22ac75382ec8de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb363c5ac5494eb2ae1ae564cd43a857": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d0be03d4cc8451da5e3f01734490d8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fffc90992b3f48bfb37e76fb1c306166": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8828e148a4c400cbd9edf2a71219619": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "508f6ab46abb40c4a117e256cd0f17a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5cf6378100044fab95e5565fb52f4e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Requirements"
      ],
      "metadata": {
        "id": "p50Dd1C_-3Hi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install facenet_pytorch"
      ],
      "metadata": {
        "id": "SpHqCWXrkVmw"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install opencv-python"
      ],
      "metadata": {
        "id": "A5enTkCvkr5u"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install unrar"
      ],
      "metadata": {
        "id": "hg_b4rYliUtY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OB4OtHjPhI0z"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "from facenet_pytorch import MTCNN, InceptionResnetV1, fixed_image_standardization, training\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import uuid\n",
        "import time\n",
        "import cv2\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Collect Data"
      ],
      "metadata": {
        "id": "JmZ3f6rlljoj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# root_dir = \"/content/Train_Data\"\n",
        "\n",
        "# for i in range(300):\n",
        "#   cap = cv2.VideoCapture(0)\n",
        "#   print(f\"Taking Picture number {i} ......\")\n",
        "#   time.sleep(5)\n",
        "#   ret, frame = cap.read()\n",
        "#   imgname = os.path.join(root_dir, f\"_{i}.jpg\")\n",
        "#   cv2.imwrite(imgname, frame)\n",
        "#   cv2.imshow('frame', frame)\n",
        "#   time.sleep(3)\n",
        "\n",
        "#   if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "#     break\n",
        "\n",
        "# cap.release()\n",
        "# cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "hgUam96Ikjx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from IPython.display import display, Javascript\n",
        "# from google.colab.output import eval_js\n",
        "# from base64 import b64decode\n",
        "\n",
        "# # def take_photo(filename='/content/Train_Data/photo.jpg', quality=0.8):\n",
        "#   # root = \"/content/Train_Data\"\n",
        "#   # filename = input(\"Image named as \")\n",
        "#   # filename = os.path.join(root, filename + \".jpg\")\n",
        "\n",
        "# def take_photo(filename, quality=0.8):\n",
        "#   js = Javascript('''\n",
        "#     async function takePhoto(quality) {\n",
        "#       const div = document.createElement('div');\n",
        "#       const capture = document.createElement('button');\n",
        "#       capture.textContent = 'Capture';\n",
        "#       div.appendChild(capture);\n",
        "\n",
        "#       const video = document.createElement('video');\n",
        "#       video.style.display = 'block';\n",
        "#       const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "#       document.body.appendChild(div);\n",
        "#       div.appendChild(video);\n",
        "#       video.srcObject = stream;\n",
        "#       await video.play();\n",
        "\n",
        "#       // Resize the output to fit the video element.\n",
        "#       google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "#       // Wait for Capture to be clicked.\n",
        "#       await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "#       const canvas = document.createElement('canvas');\n",
        "#       canvas.width = video.videoWidth;\n",
        "#       canvas.height = video.videoHeight;\n",
        "#       canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "#       stream.getVideoTracks()[0].stop();\n",
        "#       div.remove();\n",
        "#       return canvas.toDataURL('image/jpeg', quality);\n",
        "#     }\n",
        "#     ''')\n",
        "#   display(js)\n",
        "#   data = eval_js('takePhoto({})'.format(quality))\n",
        "#   binary = b64decode(data.split(',')[1])\n",
        "#   with open(filename, 'wb') as f:\n",
        "#     f.write(binary)\n",
        "#   return filename"
      ],
      "metadata": {
        "id": "nn8WeJStpkgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from IPython.display import Image\n",
        "\n",
        "# try:\n",
        "#   for index in range(9):\n",
        "#     print(f\"Taking Picture number {index+100} ......\")\n",
        "#     root = \"/content/Train_Data\"\n",
        "#     filename = os.path.join(root, \"Sample_\" + str(index) + \".jpg\")\n",
        "#     path = take_photo(filename)\n",
        "#     print('Saved to {}'.format(path))\n",
        "#     print(\"-\"*40)\n",
        "#     time.sleep(3)\n",
        "\n",
        "# except Exception as err:\n",
        "#   print(str(err))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "qFMjvyqBpkgm",
        "outputId": "0b0498eb-730d-45fd-cb28-05721a62ba30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Taking Picture number 100 ......\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved to /content/Train_Data/Sample_0.jpg\n",
            "----------------------------------------\n",
            "Taking Picture number 101 ......\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved to /content/Train_Data/Sample_1.jpg\n",
            "----------------------------------------\n",
            "Taking Picture number 102 ......\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved to /content/Train_Data/Sample_2.jpg\n",
            "----------------------------------------\n",
            "Taking Picture number 103 ......\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved to /content/Train_Data/Sample_3.jpg\n",
            "----------------------------------------\n",
            "Taking Picture number 104 ......\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved to /content/Train_Data/Sample_4.jpg\n",
            "----------------------------------------\n",
            "Taking Picture number 105 ......\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved to /content/Train_Data/Sample_5.jpg\n",
            "----------------------------------------\n",
            "Taking Picture number 106 ......\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved to /content/Train_Data/Sample_6.jpg\n",
            "----------------------------------------\n",
            "Taking Picture number 107 ......\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved to /content/Train_Data/Sample_7.jpg\n",
            "----------------------------------------\n",
            "Taking Picture number 108 ......\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved to /content/Train_Data/Sample_8.jpg\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-Tune"
      ],
      "metadata": {
        "id": "vougapO81GJd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print('Running on device: {}'.format(device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ta6m-ZaC1Ibz",
        "outputId": "7879c1bf-0e88-4339-d2aa-98535f405465"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rar_file = '/content/data.rar'\n",
        "\n",
        "# Create a directory to extract files to\n",
        "extract_dir = '/content/'\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "# Extract the RAR file\n",
        "!unrar x -r {rar_file} {extract_dir}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qx8YmlDPifd_",
        "outputId": "1ccb2369-73bb-4bb2-eb0a-a9c60e3a1509"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "UNRAR 6.11 beta 1 freeware      Copyright (c) 1993-2022 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from /content/data.rar\n",
            "\n",
            "Creating    /content/data                                             OK\n",
            "Creating    /content/data/Person1                                     OK\n",
            "Extracting  /content/data/Person1/Sample_0.jpg                           \b\b\b\b  2%\b\b\b\b\b  OK \n",
            "Extracting  /content/data/Person1/Sample_1.jpg                           \b\b\b\b  4%\b\b\b\b\b  OK \n",
            "Extracting  /content/data/Person1/Sample_10.jpg                          \b\b\b\b  6%\b\b\b\b\b  OK \n",
            "Extracting  /content/data/Person1/Sample_11.jpg                          \b\b\b\b  8%\b\b\b\b\b  OK \n",
            "Extracting  /content/data/Person1/Sample_12.jpg                          \b\b\b\b  9%\b\b\b\b\b  OK \n",
            "Extracting  /content/data/Person1/Sample_13.jpg                          \b\b\b\b 11%\b\b\b\b\b  OK \n",
            "Extracting  /content/data/Person1/Sample_14.jpg                          \b\b\b\b 13%\b\b\b\b\b  OK \n",
            "Extracting  /content/data/Person1/Sample_15.jpg                          \b\b\b\b 15%\b\b\b\b\b  OK \n",
            "Extracting  /content/data/Person1/Sample_16.jpg                          \b\b\b\b 17%\b\b\b\b\b  OK \n",
            "Extracting  /content/data/Person1/Sample_17.jpg                          \b\b\b\b 19%\b\b\b\b\b  OK \n",
            "Extracting  /content/data/Person1/Sample_18.jpg                          \b\b\b\b 21%\b\b\b\b\b  OK \n",
            "Extracting  /content/data/Person1/Sample_19.jpg                          \b\b\b\b 23%\b\b\b\b\b  OK \n",
            "Extracting  /content/data/Person1/Sample_2.jpg                           \b\b\b\b 25%\b\b\b\b\b  OK \n",
            "Extracting  /content/data/Person1/Sample_20.jpg                          \b\b\b\b 27%\b\b\b\b\b  OK \n",
            "Extracting  /content/data/Person1/Sample_21.jpg                          \b\b\b\b 29%\b\b\b\b\b  OK \n",
            "Extracting  /content/data/Person1/Sample_22.jpg                          \b\b\b\b 31%\b\b\b\b\b  OK \n",
            "Extracting  /content/data/Person1/Sample_23.jpg                          \b\b\b\b 33%\b\b\b\b\b  OK \n",
            "Extracting  /content/data/Person1/Sample_24.jpg                          \b\b\b\b 35%\b\b\b\b\b  OK \n",
            "Extracting  /content/data/Person1/Sample_25.jpg                          \b\b\b\b 37%\b\b\b\b\b  OK \n",
            "Extracting  /content/data/Person1/Sample_26.jpg                          \b\b\b\b 39%\b\b\b\b\b  OK \n",
            "Extracting  /content/data/Person1/Sample_27.jpg                          \b\b\b\b 41%\b\b\b\b\b  OK \n",
            "Extracting  /content/data/Person1/Sample_28.jpg                          \b\b\b\b 43%\b\b\b\b\b  OK \n",
            "Extracting  /content/data/Person1/Sample_29.jpg                          \b\b\b\b 45%\b\b\b\b\b  OK \n",
            "Extracting  /content/data/Person1/Sample_3.jpg                           \b\b\b\b 47%\b\b\b\b\b  OK \n",
            "Extracting  /content/data/Person1/Sample_30.jpg                          \b\b\b\b 49%\b\b\b\b\b  OK \n",
            "Extracting  /content/data/Person1/Sample_31.jpg                          \b\b\b\b 51%\b\b\b\b\b  OK \n",
            "Extracting  /content/data/Person1/Sample_32.jpg                          \b\b\b\b 53%\b\b\b\b\b  OK \n",
            "Extracting  /content/data/Person1/Sample_33.jpg                          \b\b\b\b 55%\b\b\b\b\b  OK \n",
            "Extracting  /content/data/Person1/Sample_34.jpg                          \b\b\b\b 57%\b\b\b\b\b  OK \n",
            "Extracting  /content/data/Person1/Sample_35.jpg                          \b\b\b\b 59%\b\b\b\b\b  OK \n",
            "Extracting  /content/data/Person1/Sample_36.jpg                          \b\b\b\b 61%\b\b\b\b\b  OK \n",
            "Extracting  /content/data/Person1/Sample_37.jpg                          \b\b\b\b 63%\b\b\b\b\b  OK \n",
            "Extracting  /content/data/Person1/Sample_38.jpg                          \b\b\b\b 65%\b\b\b\b\b  OK \n",
            "Extracting  /content/data/Person1/Sample_39.jpg                          \b\b\b\b 67%\b\b\b\b\b  OK \n",
            "Extracting  /content/data/Person1/Sample_4.jpg                           \b\b\b\b 69%\b\b\b\b\b  OK \n",
            "Extracting  /content/data/Person1/Sample_40.jpg                          \b\b\b\b 71%\b\b\b\b\b  OK \n",
            "Extracting  /content/data/Person1/Sample_41.jpg                          \b\b\b\b 73%\b\b\b\b\b  OK \n",
            "Extracting  /content/data/Person1/Sample_42.jpg                          \b\b\b\b 75%\b\b\b\b\b  OK \n",
            "Extracting  /content/data/Person1/Sample_44.jpg                          \b\b\b\b 77%\b\b\b\b\b  OK \n",
            "Extracting  /content/data/Person1/Sample_45.jpg                          \b\b\b\b 79%\b\b\b\b\b  OK \n",
            "Extracting  /content/data/Person1/Sample_46.jpg                          \b\b\b\b 81%\b\b\b\b\b  OK \n",
            "Extracting  /content/data/Person1/Sample_47.jpg                          \b\b\b\b 83%\b\b\b\b\b  OK \n",
            "Extracting  /content/data/Person1/Sample_48.jpg                          \b\b\b\b 85%\b\b\b\b\b  OK \n",
            "Extracting  /content/data/Person1/Sample_49.jpg                          \b\b\b\b 87%\b\b\b\b\b  OK \n",
            "Extracting  /content/data/Person1/Sample_5.jpg                           \b\b\b\b 89%\b\b\b\b\b  OK \n",
            "Extracting  /content/data/Person1/Sample_50.jpg                          \b\b\b\b 91%\b\b\b\b\b  OK \n",
            "Extracting  /content/data/Person1/Sample_6.jpg                           \b\b\b\b 93%\b\b\b\b\b  OK \n",
            "Extracting  /content/data/Person1/Sample_7.jpg                           \b\b\b\b 95%\b\b\b\b\b  OK \n",
            "Extracting  /content/data/Person1/Sample_8.jpg                           \b\b\b\b 98%\b\b\b\b\b  OK \n",
            "Extracting  /content/data/Person1/Sample_9.jpg                           \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(os.listdir(\"/content/data/Person1\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uo9Hlewt1OE9",
        "outputId": "dbe6abc6-bb93-4dc8-bd75-4e50600eae83"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/data/'\n",
        "\n",
        "batch_size = 16\n",
        "epochs = 30\n",
        "workers = 0 if os.name == 'nt' else 8"
      ],
      "metadata": {
        "id": "1UeW86F718po"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mtcnn = MTCNN(\n",
        "    image_size=160, margin=0, min_face_size=20,\n",
        "    thresholds=[0.6, 0.7, 0.7], factor=0.709, post_process=True,\n",
        "    device=device\n",
        ")"
      ],
      "metadata": {
        "id": "cCeENoIJ4mXu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = datasets.ImageFolder(data_dir, transform=transforms.Resize((512, 512)))\n",
        "dataset.samples = [\n",
        "    (p, p.replace(data_dir, data_dir + '_cropped'))\n",
        "        for p, _ in dataset.samples\n",
        "]\n",
        "\n",
        "loader = DataLoader(\n",
        "    dataset,\n",
        "    num_workers=workers,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=training.collate_pil\n",
        ")\n",
        "\n",
        "for i, (x, y) in enumerate(loader):\n",
        "    mtcnn(x, save_path=y)\n",
        "    print('\\rBatch {} of {}'.format(i + 1, len(loader)), end='')\n",
        "\n",
        "# Remove mtcnn to reduce GPU memory usage\n",
        "del mtcnn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lq5IhvgF4plC",
        "outputId": "a2c2eb77-6f29-44ae-8cf3-061336294026"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 3 of 4"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rBatch 4 of 4"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -R /content/data/Person1\n",
        "# !ls /content/data -a   #to make sure that the deletion has occurred"
      ],
      "metadata": {
        "id": "e5CG0qmb7eQa"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !zip -r /content/dataset.zip /content/data"
      ],
      "metadata": {
        "id": "KdIeqUrF6fzp"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet = InceptionResnetV1(\n",
        "    classify=True,\n",
        "    pretrained='vggface2',\n",
        "    num_classes=len(dataset.class_to_idx)\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "PvKuPR1L8SKB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "3e0952d256f8459eb1ab8d883fe314b3",
            "66c597dafa524766b01547ea36fe19e8",
            "f71059c1b5524ade9e0f95d706ba7068",
            "86c8932bb8d044aeb8f703f2ee901c83",
            "b8f80395b11b4804aa22ac75382ec8de",
            "eb363c5ac5494eb2ae1ae564cd43a857",
            "2d0be03d4cc8451da5e3f01734490d8e",
            "fffc90992b3f48bfb37e76fb1c306166",
            "a8828e148a4c400cbd9edf2a71219619",
            "508f6ab46abb40c4a117e256cd0f17a5",
            "b5cf6378100044fab95e5565fb52f4e0"
          ]
        },
        "outputId": "e5272b3e-eca6-4043-d1ff-56a398c46205"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/107M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3e0952d256f8459eb1ab8d883fe314b3"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> Error Handling:\n",
        "\n",
        "A hidden .ipynb file causes error, so make sure to run the cells bellow with respect to the directory of your dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "TUbKLmxo_GZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -R /content/data/.ipynb_checkpoints"
      ],
      "metadata": {
        "id": "LRT5UmAc96Pc"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -R /content/data/Person1/.ipynb_checkpoints"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3W-1Xl6997_",
        "outputId": "8b71da8b-ba34-4219-8c90-6676b15b60ff"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/data/Person1/.ipynb_checkpoints': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(resnet.parameters(), lr=0.001)\n",
        "scheduler = MultiStepLR(optimizer, [5, 10])\n",
        "\n",
        "trans = transforms.Compose([\n",
        "    np.float32,\n",
        "    transforms.ToTensor(),\n",
        "    fixed_image_standardization\n",
        "])\n",
        "\n",
        "dataset = datasets.ImageFolder(\"/content/data/\", transform=trans)\n",
        "img_inds = np.arange(len(dataset))\n",
        "np.random.shuffle(img_inds)\n",
        "train_inds = img_inds[:int(0.8 * len(img_inds))]\n",
        "val_inds = img_inds[int(0.8 * len(img_inds)):]\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset,\n",
        "    num_workers=workers,\n",
        "    batch_size=batch_size,\n",
        "    sampler=SubsetRandomSampler(train_inds)\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    dataset,\n",
        "    num_workers=workers,\n",
        "    batch_size=batch_size,\n",
        "    sampler=SubsetRandomSampler(val_inds)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_0aNUMb6DYJ",
        "outputId": "bf3ea8c5-fc56-42e0-eb5f-da83d1e1928a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "metrics = {\n",
        "    'fps': training.BatchTimer(),\n",
        "    'acc': training.accuracy\n",
        "}"
      ],
      "metadata": {
        "id": "Z_6ZTAml6Dqj"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer = SummaryWriter()\n",
        "writer.iteration, writer.interval = 0, 10\n",
        "\n",
        "print('\\n\\nInitial')\n",
        "print('-' * 10)\n",
        "resnet.eval()\n",
        "training.pass_epoch(\n",
        "    resnet, loss_fn, val_loader,\n",
        "    batch_metrics=metrics, show_running=True, device=device,\n",
        "    writer=writer\n",
        ")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print('\\nEpoch {}/{}'.format(epoch + 1, epochs))\n",
        "    print('-' * 10)\n",
        "\n",
        "    resnet.train()\n",
        "    training.pass_epoch(\n",
        "        resnet, loss_fn, train_loader, optimizer, scheduler,\n",
        "        batch_metrics=metrics, show_running=True, device=device,\n",
        "        writer=writer\n",
        "    )\n",
        "\n",
        "    resnet.eval()\n",
        "    training.pass_epoch(\n",
        "        resnet, loss_fn, val_loader,\n",
        "        batch_metrics=metrics, show_running=True, device=device,\n",
        "        writer=writer\n",
        "    )\n",
        "\n",
        "writer.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1DklN5e-LND",
        "outputId": "4c0cb1a1-7100-4c16-b034-f7fb53746287"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Initial\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rValid |     1/1    | loss:    0.0000 | fps:    0.5092 | acc:    1.0000   \n",
            "\n",
            "Epoch 1/30\n",
            "----------\n",
            "Train |     3/3    | loss:    0.0000 | fps:    2.5868 | acc:    1.0000   \n",
            "Valid |     1/1    | loss:    0.0000 | fps:    5.1826 | acc:    1.0000   \n",
            "\n",
            "Epoch 2/30\n",
            "----------\n",
            "Train |     3/3    | loss:    0.0000 | fps:    2.6611 | acc:    1.0000   \n",
            "Valid |     1/1    | loss:    0.0000 | fps:    4.5213 | acc:    1.0000   \n",
            "\n",
            "Epoch 3/30\n",
            "----------\n",
            "Train |     3/3    | loss:    0.0000 | fps:    2.6767 | acc:    1.0000   \n",
            "Valid |     1/1    | loss:    0.0000 | fps:    4.5198 | acc:    1.0000   \n",
            "\n",
            "Epoch 4/30\n",
            "----------\n",
            "Train |     3/3    | loss:    0.0000 | fps:    2.6315 | acc:    1.0000   \n",
            "Valid |     1/1    | loss:    0.0000 | fps:    4.4488 | acc:    1.0000   \n",
            "\n",
            "Epoch 5/30\n",
            "----------\n",
            "Train |     3/3    | loss:    0.0000 | fps:    2.6134 | acc:    1.0000   \n",
            "Valid |     1/1    | loss:    0.0000 | fps:    2.8543 | acc:    1.0000   \n",
            "\n",
            "Epoch 6/30\n",
            "----------\n",
            "Train |     3/3    | loss:    0.0000 | fps:    1.9094 | acc:    1.0000   \n",
            "Valid |     1/1    | loss:    0.0000 | fps:    3.4944 | acc:    1.0000   \n",
            "\n",
            "Epoch 7/30\n",
            "----------\n",
            "Train |     3/3    | loss:    0.0000 | fps:    2.2021 | acc:    1.0000   \n",
            "Valid |     1/1    | loss:    0.0000 | fps:    4.6626 | acc:    1.0000   \n",
            "\n",
            "Epoch 8/30\n",
            "----------\n",
            "Train |     3/3    | loss:    0.0000 | fps:    2.4299 | acc:    1.0000   \n",
            "Valid |     1/1    | loss:    0.0000 | fps:    4.5037 | acc:    1.0000   \n",
            "\n",
            "Epoch 9/30\n",
            "----------\n",
            "Train |     3/3    | loss:    0.0000 | fps:    2.1152 | acc:    1.0000   \n",
            "Valid |     1/1    | loss:    0.0000 | fps:    1.8121 | acc:    1.0000   \n",
            "\n",
            "Epoch 10/30\n",
            "----------\n",
            "Train |     3/3    | loss:    0.0000 | fps:    2.3357 | acc:    1.0000   \n",
            "Valid |     1/1    | loss:    0.0000 | fps:    4.4757 | acc:    1.0000   \n",
            "\n",
            "Epoch 11/30\n",
            "----------\n",
            "Train |     3/3    | loss:    0.0000 | fps:    2.1172 | acc:    1.0000   \n",
            "Valid |     1/1    | loss:    0.0000 | fps:    4.5467 | acc:    1.0000   \n",
            "\n",
            "Epoch 12/30\n",
            "----------\n",
            "Train |     3/3    | loss:    0.0000 | fps:    1.5855 | acc:    1.0000   \n",
            "Valid |     1/1    | loss:    0.0000 | fps:    4.2492 | acc:    1.0000   \n",
            "\n",
            "Epoch 13/30\n",
            "----------\n",
            "Train |     3/3    | loss:    0.0000 | fps:    2.3204 | acc:    1.0000   \n",
            "Valid |     1/1    | loss:    0.0000 | fps:    3.8906 | acc:    1.0000   \n",
            "\n",
            "Epoch 14/30\n",
            "----------\n",
            "Train |     3/3    | loss:    0.0000 | fps:    2.4045 | acc:    1.0000   \n",
            "Valid |     1/1    | loss:    0.0000 | fps:    4.0590 | acc:    1.0000   \n",
            "\n",
            "Epoch 15/30\n",
            "----------\n",
            "Train |     3/3    | loss:    0.0000 | fps:    2.7974 | acc:    1.0000   \n",
            "Valid |     1/1    | loss:    0.0000 | fps:    4.9823 | acc:    1.0000   \n",
            "\n",
            "Epoch 16/30\n",
            "----------\n",
            "Train |     3/3    | loss:    0.0000 | fps:    2.5114 | acc:    1.0000   \n",
            "Valid |     1/1    | loss:    0.0000 | fps:    3.1202 | acc:    1.0000   \n",
            "\n",
            "Epoch 17/30\n",
            "----------\n",
            "Train |     3/3    | loss:    0.0000 | fps:    2.2297 | acc:    1.0000   \n",
            "Valid |     1/1    | loss:    0.0000 | fps:    4.3517 | acc:    1.0000   \n",
            "\n",
            "Epoch 18/30\n",
            "----------\n",
            "Train |     3/3    | loss:    0.0000 | fps:    2.5085 | acc:    1.0000   \n",
            "Valid |     1/1    | loss:    0.0000 | fps:    4.1812 | acc:    1.0000   \n",
            "\n",
            "Epoch 19/30\n",
            "----------\n",
            "Train |     3/3    | loss:    0.0000 | fps:    2.6212 | acc:    1.0000   \n",
            "Valid |     1/1    | loss:    0.0000 | fps:    4.2252 | acc:    1.0000   \n",
            "\n",
            "Epoch 20/30\n",
            "----------\n",
            "Train |     3/3    | loss:    0.0000 | fps:    2.4859 | acc:    1.0000   \n",
            "Valid |     1/1    | loss:    0.0000 | fps:    4.0509 | acc:    1.0000   \n",
            "\n",
            "Epoch 21/30\n",
            "----------\n",
            "Train |     3/3    | loss:    0.0000 | fps:    2.5907 | acc:    1.0000   \n",
            "Valid |     1/1    | loss:    0.0000 | fps:    4.4196 | acc:    1.0000   \n",
            "\n",
            "Epoch 22/30\n",
            "----------\n",
            "Train |     3/3    | loss:    0.0000 | fps:    2.5509 | acc:    1.0000   \n",
            "Valid |     1/1    | loss:    0.0000 | fps:    3.7345 | acc:    1.0000   \n",
            "\n",
            "Epoch 23/30\n",
            "----------\n",
            "Train |     3/3    | loss:    0.0000 | fps:    2.3377 | acc:    1.0000   \n",
            "Valid |     1/1    | loss:    0.0000 | fps:    4.0174 | acc:    1.0000   \n",
            "\n",
            "Epoch 24/30\n",
            "----------\n",
            "Train |     3/3    | loss:    0.0000 | fps:    2.4663 | acc:    1.0000   \n",
            "Valid |     1/1    | loss:    0.0000 | fps:    4.1856 | acc:    1.0000   \n",
            "\n",
            "Epoch 25/30\n",
            "----------\n",
            "Train |     3/3    | loss:    0.0000 | fps:    2.5743 | acc:    1.0000   \n",
            "Valid |     1/1    | loss:    0.0000 | fps:    4.2935 | acc:    1.0000   \n",
            "\n",
            "Epoch 26/30\n",
            "----------\n",
            "Train |     3/3    | loss:    0.0000 | fps:    2.4414 | acc:    1.0000   \n",
            "Valid |     1/1    | loss:    0.0000 | fps:    4.2185 | acc:    1.0000   \n",
            "\n",
            "Epoch 27/30\n",
            "----------\n",
            "Train |     3/3    | loss:    0.0000 | fps:    2.6048 | acc:    1.0000   \n",
            "Valid |     1/1    | loss:    0.0000 | fps:    4.7553 | acc:    1.0000   \n",
            "\n",
            "Epoch 28/30\n",
            "----------\n",
            "Train |     3/3    | loss:    0.0000 | fps:    2.5663 | acc:    1.0000   \n",
            "Valid |     1/1    | loss:    0.0000 | fps:    3.6225 | acc:    1.0000   \n",
            "\n",
            "Epoch 29/30\n",
            "----------\n",
            "Train |     3/3    | loss:    0.0000 | fps:    2.0720 | acc:    1.0000   \n",
            "Valid |     1/1    | loss:    0.0000 | fps:    3.3142 | acc:    1.0000   \n",
            "\n",
            "Epoch 30/30\n",
            "----------\n",
            "Train |     3/3    | loss:    0.0000 | fps:    2.6978 | acc:    1.0000   \n",
            "Valid |     1/1    | loss:    0.0000 | fps:    4.5815 | acc:    1.0000   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(resnet.state_dict(), '/content/facenet_model_final.pth')"
      ],
      "metadata": {
        "id": "tBLO8720-Lov"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6bJsfTUKNLpG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}