{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MHosseinHashemi/Face-Recognition-System/blob/main/Second_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p50Dd1C_-3Hi"
      },
      "source": [
        "# Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpHqCWXrkVmw"
      },
      "outputs": [],
      "source": [
        "!pip install facenet_pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "A5enTkCvkr5u"
      },
      "outputs": [],
      "source": [
        "# !pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hg_b4rYliUtY",
        "outputId": "d334c524-f376-4775-ed7e-3fd0cab383cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: unrar in /usr/local/lib/python3.10/dist-packages (0.4)\n"
          ]
        }
      ],
      "source": [
        "# !pip install unrar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OB4OtHjPhI0z"
      },
      "outputs": [],
      "source": [
        "from torch import optim\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "from facenet_pytorch import MTCNN, InceptionResnetV1, fixed_image_standardization, training\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import torch\n",
        "import uuid\n",
        "import time\n",
        "import cv2\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmZ3f6rlljoj"
      },
      "source": [
        "# Collect Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgUam96Ikjx_"
      },
      "outputs": [],
      "source": [
        "# root_dir = \"/content/Train_Data\"\n",
        "\n",
        "# for i in range(300):\n",
        "#   cap = cv2.VideoCapture(0)\n",
        "#   print(f\"Taking Picture number {i} ......\")\n",
        "#   time.sleep(5)\n",
        "#   ret, frame = cap.read()\n",
        "#   imgname = os.path.join(root_dir, f\"_{i}.jpg\")\n",
        "#   cv2.imwrite(imgname, frame)\n",
        "#   cv2.imshow('frame', frame)\n",
        "#   time.sleep(3)\n",
        "\n",
        "#   if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "#     break\n",
        "\n",
        "# cap.release()\n",
        "# cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nn8WeJStpkgg"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "# def take_photo(filename='/content/Train_Data/photo.jpg', quality=0.8):\n",
        "  # root = \"/content/Train_Data\"\n",
        "  # filename = input(\"Image named as \")\n",
        "  # filename = os.path.join(root, filename + \".jpg\")\n",
        "\n",
        "def take_photo(filename, quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "qFMjvyqBpkgm"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "try:\n",
        "  for index in range(111,500):\n",
        "    print(f\"Taking Picture number {index+1}/500 ......\")\n",
        "    root = \"/content/Train_Data\"\n",
        "    filename = os.path.join(root, \"Sample_\" + str(index) + \".jpg\")\n",
        "    path = take_photo(filename)\n",
        "    print('Saved to {}'.format(path))\n",
        "    print(\"-\"*50)\n",
        "    time.sleep(2)\n",
        "\n",
        "except Exception as err:\n",
        "  print(str(err))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97LrsKErdE7K"
      },
      "source": [
        "# Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "5vZVTxrVlmvP"
      },
      "outputs": [],
      "source": [
        "!unzip /content/dataset.zip -d /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "1gPnzzcZdEL5"
      },
      "outputs": [],
      "source": [
        "import Data_and_Label_Augmentation as DataGen\n",
        "\n",
        "#### Initialize Image Custom Augmentation object\n",
        "my_data = DataGen.Image_Custom_Augmentation(SP_intensity=False,  # Salt and Pepper Intensity\n",
        "                                            RO_Key=15,           # Rotation Intensity\n",
        "                                            Br_intensity=15,     # Brightness Intensity\n",
        "                                            H_Key=True,          # Horizontal Flip\n",
        "                                            V_Key=False,         # Vertical Flip\n",
        "                                            HE_Key=False,        # Histogram Equalization\n",
        "                                            Img_res= 512)        # Image Resolution\n",
        "\n",
        "#### Generate augmented data\n",
        "my_data.Generate_Data(input_path=\"/content/dataset/Person1\", output_path=\"/content/dataset/Person1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vougapO81GJd"
      },
      "source": [
        "# Fine-Tune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ta6m-ZaC1Ibz",
        "outputId": "0bd8b25d-0300-45d0-a729-806cc4310ce3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on device: cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print('Running on device: {}'.format(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Qx8YmlDPifd_"
      },
      "outputs": [],
      "source": [
        "# rar_file = '/content/data.rar'\n",
        "\n",
        "# # Create a directory to extract files to\n",
        "# extract_dir = '/content/'\n",
        "# os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "# # Extract the RAR file\n",
        "# !unrar x -r /content/data.rar /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5CG0qmb7eQa"
      },
      "outputs": [],
      "source": [
        "# !rm -R /content/data/_croppedPerson1\n",
        "# !ls /content/data -a   #to make sure that the deletion has occurred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdIeqUrF6fzp"
      },
      "outputs": [],
      "source": [
        "# !zip -r /content/dataset.zip /content/dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUbKLmxo_GZZ"
      },
      "source": [
        "\n",
        "\n",
        "> Error Handling:\n",
        "\n",
        "A hidden .ipynb file causes error, so make sure to run the cells bellow with respect to the directory of your dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRT5UmAc96Pc",
        "outputId": "6fd754d4-4116-47a3-e542-4c2141569e01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rm: cannot remove '/content/dataset/.ipynb_checkpoints': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!rm -R /content/dataset/.ipynb_checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3W-1Xl6997_",
        "outputId": "8e43f924-0f2e-48cc-902f-57f45e77282a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rm: cannot remove '/content/dataset/Person1/.ipynb_checkpoints': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!rm -R /content/dataset/Person1/.ipynb_checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "0X5ydWn7bdyv"
      },
      "outputs": [],
      "source": [
        "# !unzip /content/dataset.zip -d /content/dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXIX-2TBfRKj"
      },
      "outputs": [],
      "source": [
        "data_dir = '/content/dataset'\n",
        "\n",
        "batch_size = 16\n",
        "epochs = 20\n",
        "workers = 0 if os.name == 'nt' else 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FrMx73R70-at"
      },
      "outputs": [],
      "source": [
        "# D_gen = DataGen.Image_Custom_Augmentation(RO_Key=30, Br_intensity=30, H_Key=True, Img_res=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pS4sCQg14QJL",
        "outputId": "e628e4a7-c701-4e29-859e-1f38b119515e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [00:02<00:00, 23.42it/s]\n"
          ]
        }
      ],
      "source": [
        "# D_gen.Generate_Data(input_path=\"/content/data/Person1\", output_path=\"/content/augmented_data/Person1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TTHyl_bfRUA"
      },
      "outputs": [],
      "source": [
        "mtcnn = MTCNN(\n",
        "    image_size=160, margin=0, min_face_size=20,\n",
        "    thresholds=[0.6, 0.7, 0.7], factor=0.709, post_process=True,\n",
        "    device=device\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6UksCkpfRXJ",
        "outputId": "8dd1f7f0-859f-4596-fc00-cdb868bc34b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 63 of 63"
          ]
        }
      ],
      "source": [
        "dataset = datasets.ImageFolder(data_dir, transform=transforms.Resize((512, 512)))\n",
        "dataset.samples = [\n",
        "    (p, p.replace(data_dir, data_dir + '_cropped'))\n",
        "        for p, _ in dataset.samples\n",
        "]\n",
        "\n",
        "loader = DataLoader(\n",
        "    dataset,\n",
        "    num_workers=workers,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=training.collate_pil\n",
        ")\n",
        "\n",
        "for i, (x, y) in enumerate(loader):\n",
        "    mtcnn(x, save_path=y)\n",
        "    print('\\rBatch {} of {}'.format(i + 1, len(loader)), end='')\n",
        "\n",
        "# Remove mtcnn to reduce GPU memory usage\n",
        "del mtcnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "a1b2b7007807456c99e121b3a55e8921",
            "13f8c65d7ac048e4a10d0fe9e18d7c81",
            "b64777f0f9ea496b886e2c5f7bdfb22b",
            "2c902c06d4494b03929bcce6a2854bfb",
            "2ff63059fdeb463b994fdf32e2171dbe",
            "0ed1b107330d456e935460c7bc7e8b22",
            "69c9485d535c470fa916f7f3511fe5e1",
            "1322f158b3eb46d2acab941ffea9cd83",
            "beee37b2466243068a1e257fd1ea66b7",
            "b8ff1d3b61424e78b276af9849764b43",
            "4f5c11a1b0a74247a2b63f7fa08194ff"
          ]
        },
        "id": "R23ktHUAfRgN",
        "outputId": "67c63220-a889-46e0-aa90-6ac78320f626"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a1b2b7007807456c99e121b3a55e8921",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0.00/107M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "resnet = InceptionResnetV1(\n",
        "    classify=True,\n",
        "    pretrained='vggface2',\n",
        "    num_classes=len(dataset.class_to_idx)\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pakVTqEfRiz",
        "outputId": "ee93e151-f304-43f7-8dcf-872e35fc915e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rm: cannot remove '/content/dataset_cropped/.ipynb_checkpoints': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!rm -R /content/dataset_cropped/.ipynb_checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSgEBftV2Hv0",
        "outputId": "fa793323-c5d4-430a-ba2b-30dd5ef21148"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rm: cannot remove '/content/dataset_cropped/Person1/.ipynb_checkpoints': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!rm -R /content/dataset_cropped/Person1/.ipynb_checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "213xKvVh2HyY"
      },
      "outputs": [],
      "source": [
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "optimizer = optim.Adam(resnet.parameters(), lr=0.001)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
        "\n",
        "\n",
        "trans = transforms.Compose([\n",
        "    np.float32,\n",
        "    transforms.ToTensor(),\n",
        "    fixed_image_standardization\n",
        "])\n",
        "\n",
        "dataset = datasets.ImageFolder(\"/content/dataset_cropped\", transform=trans)\n",
        "img_inds = np.arange(len(dataset))\n",
        "np.random.shuffle(img_inds)\n",
        "train_inds = img_inds[:int(0.9 * len(img_inds))]\n",
        "val_inds = img_inds[int(0.9 * len(img_inds)):]\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset,\n",
        "    num_workers=workers,\n",
        "    batch_size=batch_size,\n",
        "    sampler=SubsetRandomSampler(train_inds)\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    dataset,\n",
        "    num_workers=workers,\n",
        "    batch_size=batch_size,\n",
        "    sampler=SubsetRandomSampler(val_inds)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "he0hIFNz2H07"
      },
      "outputs": [],
      "source": [
        "# loss_fn = torch.nn.CrossEntropyLoss()\n",
        "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "# metrics = {\n",
        "#     'fps': training.BatchTimer(),\n",
        "#     'acc': training.accuracy\n",
        "# }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGTmFVnG2H3c"
      },
      "outputs": [],
      "source": [
        "def compute_accuracy(y_pred, y_true):\n",
        "    y_pred_binary = (y_pred > 0.5).float()\n",
        "    correct = (y_pred_binary == y_true).sum().item()\n",
        "    total = y_true.size(0)\n",
        "    accuracy = correct / total\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElhHYyqz2H50",
        "outputId": "d180f887-b306-4a24-d52f-238053c74cdc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/20\n",
            "Train Loss: 0.6519\n",
            "Train Accuracy: 0.8833\n",
            "Validation Loss: 0.3477\n",
            "Validation Accuracy: 1.0000\n",
            "====================================================================================================\n",
            "\n",
            "Epoch 2/20\n",
            "Train Loss: 0.2505\n",
            "Train Accuracy: 0.9989\n",
            "Validation Loss: 0.3226\n",
            "Validation Accuracy: 0.9500\n",
            "====================================================================================================\n",
            "\n",
            "Epoch 3/20\n",
            "Train Loss: 0.0638\n",
            "Train Accuracy: 0.9989\n",
            "Validation Loss: 0.0324\n",
            "Validation Accuracy: 1.0000\n",
            "====================================================================================================\n",
            "\n",
            "Epoch 4/20\n",
            "Train Loss: 0.0227\n",
            "Train Accuracy: 1.0000\n",
            "Validation Loss: 1.1499\n",
            "Validation Accuracy: 0.9000\n",
            "====================================================================================================\n",
            "\n",
            "Epoch 5/20\n",
            "Train Loss: 0.0223\n",
            "Train Accuracy: 0.9989\n",
            "Validation Loss: 0.0144\n",
            "Validation Accuracy: 1.0000\n",
            "====================================================================================================\n",
            "\n",
            "Epoch 6/20\n",
            "Train Loss: 0.0174\n",
            "Train Accuracy: 0.9967\n",
            "Validation Loss: 0.0083\n",
            "Validation Accuracy: 1.0000\n",
            "====================================================================================================\n",
            "\n",
            "Epoch 7/20\n",
            "Train Loss: 0.0093\n",
            "Train Accuracy: 0.9989\n",
            "Validation Loss: 0.0059\n",
            "Validation Accuracy: 1.0000\n",
            "====================================================================================================\n",
            "\n",
            "Epoch 8/20\n",
            "Train Loss: 0.0058\n",
            "Train Accuracy: 0.9989\n",
            "Validation Loss: 0.0041\n",
            "Validation Accuracy: 1.0000\n",
            "====================================================================================================\n",
            "\n",
            "Epoch 9/20\n",
            "Train Loss: 0.0041\n",
            "Train Accuracy: 1.0000\n",
            "Validation Loss: 0.0025\n",
            "Validation Accuracy: 1.0000\n",
            "====================================================================================================\n",
            "\n",
            "Epoch 10/20\n",
            "Train Loss: 0.0021\n",
            "Train Accuracy: 1.0000\n",
            "Validation Loss: 0.0018\n",
            "Validation Accuracy: 1.0000\n",
            "====================================================================================================\n",
            "\n",
            "Epoch 11/20\n",
            "Train Loss: 0.0014\n",
            "Train Accuracy: 1.0000\n",
            "Validation Loss: 0.0012\n",
            "Validation Accuracy: 1.0000\n",
            "====================================================================================================\n",
            "\n",
            "Epoch 12/20\n",
            "Train Loss: 0.0010\n",
            "Train Accuracy: 1.0000\n",
            "Validation Loss: 0.0008\n",
            "Validation Accuracy: 1.0000\n",
            "====================================================================================================\n",
            "\n",
            "Epoch 13/20\n",
            "Train Loss: 0.0009\n",
            "Train Accuracy: 1.0000\n",
            "Validation Loss: 0.0007\n",
            "Validation Accuracy: 1.0000\n",
            "====================================================================================================\n",
            "\n",
            "Epoch 14/20\n",
            "Train Loss: 0.0015\n",
            "Train Accuracy: 1.0000\n",
            "Validation Loss: 0.0008\n",
            "Validation Accuracy: 1.0000\n",
            "====================================================================================================\n",
            "\n",
            "Epoch 15/20\n",
            "Train Loss: 0.0010\n",
            "Train Accuracy: 1.0000\n",
            "Validation Loss: 0.0009\n",
            "Validation Accuracy: 1.0000\n",
            "====================================================================================================\n",
            "\n",
            "Epoch 16/20\n",
            "Train Loss: 0.0008\n",
            "Train Accuracy: 1.0000\n",
            "Validation Loss: 0.0008\n",
            "Validation Accuracy: 1.0000\n",
            "====================================================================================================\n",
            "\n",
            "Epoch 17/20\n",
            "Train Loss: 0.0006\n",
            "Train Accuracy: 1.0000\n",
            "Validation Loss: 0.0007\n",
            "Validation Accuracy: 1.0000\n",
            "====================================================================================================\n",
            "\n",
            "Epoch 18/20\n",
            "Train Loss: 0.0006\n",
            "Train Accuracy: 1.0000\n",
            "Validation Loss: 0.0005\n",
            "Validation Accuracy: 1.0000\n",
            "====================================================================================================\n",
            "\n",
            "Epoch 19/20\n",
            "Train Loss: 0.0005\n",
            "Train Accuracy: 1.0000\n",
            "Validation Loss: 0.0005\n",
            "Validation Accuracy: 1.0000\n",
            "====================================================================================================\n",
            "\n",
            "Epoch 20/20\n",
            "Train Loss: 0.0004\n",
            "Train Accuracy: 1.0000\n",
            "Validation Loss: 0.0004\n",
            "Validation Accuracy: 1.0000\n",
            "====================================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    print('\\nEpoch {}/{}'.format(epoch + 1, epochs))\n",
        "\n",
        "    # Training loop\n",
        "    resnet.train()\n",
        "    train_loss = 0.0\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "\n",
        "    resnet.train()\n",
        "    for x, y in train_loader:\n",
        "        y = y.float().unsqueeze(1).to(device)\n",
        "        y_pred = resnet(x.to(device))\n",
        "        loss_batch = loss_fn(y_pred, y)\n",
        "\n",
        "        # Backpropagation and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss_batch.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Loss Report\n",
        "        train_loss += loss_batch.item() * x.size(0)\n",
        "        y_pred_binary = (y_pred > 0.5).float()\n",
        "        train_correct += (y_pred_binary == y).sum().item()\n",
        "        train_total += y.size(0)\n",
        "\n",
        "    train_loss /= train_total\n",
        "    train_accuracy = train_correct / train_total\n",
        "\n",
        "    print(f\"Train Loss: {train_loss:.4f}\")\n",
        "    print(f\"Train Accuracy: {train_accuracy:.4f}\")\n",
        "\n",
        "\n",
        "    # Validation Loop\n",
        "    resnet.eval()\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for x, y in val_loader:\n",
        "          y = y.float().unsqueeze(1).to(device)\n",
        "          y_pred = resnet(x.to(device))\n",
        "          loss_batch = loss_fn(y_pred, y)\n",
        "\n",
        "          val_loss += loss_batch.item() * x.size(0)\n",
        "          y_pred_binary = (y_pred > 0.5).float()\n",
        "          val_correct += (y_pred_binary == y).sum().item()\n",
        "          val_total += y.size(0)\n",
        "\n",
        "    val_loss /= val_total\n",
        "    val_accuracy = val_correct / val_total\n",
        "    print(f\"Validation Loss: {val_loss:.4f}\")\n",
        "    print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
        "    print(\"=\"*100)\n",
        "\n",
        "    scheduler.step(val_loss)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tBLO8720-Lov"
      },
      "outputs": [],
      "source": [
        "# torch.save(resnet.state_dict(), '/content/facenet_model_final.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bJsfTUKNLpG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMqgH8Rl0zEtBFRpwpBsDYz",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0ed1b107330d456e935460c7bc7e8b22": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1322f158b3eb46d2acab941ffea9cd83": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13f8c65d7ac048e4a10d0fe9e18d7c81": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ed1b107330d456e935460c7bc7e8b22",
            "placeholder": "​",
            "style": "IPY_MODEL_69c9485d535c470fa916f7f3511fe5e1",
            "value": "100%"
          }
        },
        "2c902c06d4494b03929bcce6a2854bfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8ff1d3b61424e78b276af9849764b43",
            "placeholder": "​",
            "style": "IPY_MODEL_4f5c11a1b0a74247a2b63f7fa08194ff",
            "value": " 107M/107M [00:01&lt;00:00, 90.1MB/s]"
          }
        },
        "2ff63059fdeb463b994fdf32e2171dbe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f5c11a1b0a74247a2b63f7fa08194ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69c9485d535c470fa916f7f3511fe5e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1b2b7007807456c99e121b3a55e8921": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_13f8c65d7ac048e4a10d0fe9e18d7c81",
              "IPY_MODEL_b64777f0f9ea496b886e2c5f7bdfb22b",
              "IPY_MODEL_2c902c06d4494b03929bcce6a2854bfb"
            ],
            "layout": "IPY_MODEL_2ff63059fdeb463b994fdf32e2171dbe"
          }
        },
        "b64777f0f9ea496b886e2c5f7bdfb22b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1322f158b3eb46d2acab941ffea9cd83",
            "max": 111898327,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_beee37b2466243068a1e257fd1ea66b7",
            "value": 111898327
          }
        },
        "b8ff1d3b61424e78b276af9849764b43": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "beee37b2466243068a1e257fd1ea66b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}